"""
Main RAG Pipeline combining all components
"""

from src.logger import PerformanceLogger
from src.vector_store import SanskritVectorStore
from src.document_loader import SanskritDocumentLoader
from src.llm_generator import SanskritLLMGenerator

from src.config import DATA_DIR, MODEL_DIR, TOP_K_DOCS, CHUNK_SIZE
from typing import Dict
import time
import os

class SanskritRAGPipeline:
    def __init__(self, data_dir: str = DATA_DIR):
        print("\n" + "="*70)
        print("üïâÔ∏è  Sanskrit RAG System - Initialization")
        print("="*70 + "\n")
        
        # Initialize components
        self.loader = SanskritDocumentLoader(data_dir)
        self.vector_store = SanskritVectorStore()
        self.llm = SanskritLLMGenerator()
        self.logger = PerformanceLogger()
        
        # Setup pipeline
        self._setup_pipeline()
    
    def _setup_pipeline(self):
        """Setup the complete RAG pipeline"""
        try:
            # Load documents
            documents = self.loader.load_documents()
            
            if not documents:
                print("‚ùå No documents found! Please add .txt files to the data/ directory.")
                return
            
            # Chunk documents
            chunks = self.loader.chunk_documents(chunk_size=CHUNK_SIZE)
            
            # Build vector index with caching
            cache_path = os.path.join(MODEL_DIR, "embeddings.pkl")
            self.vector_store.build_index(chunks, cache_path=cache_path)
            
            print("\n" + "="*70)
            print("‚úÖ RAG Pipeline Ready!")
            print("="*70 + "\n")
            
        except Exception as e:
            print(f"\n‚ùå Error during setup: {e}")
            raise
    
    def query(self, question: str, k: int = TOP_K_DOCS, use_llm: bool = True) -> Dict:
        """Process a query through the RAG pipeline"""
        start_time = time.time()
        
        try:
            print("\n" + "‚îÄ"*70)
            print(f"üîç Query: {question}")
            print("‚îÄ"*70)
            
            # Step 1: Retrieve relevant documents
            print(f"\nüìö Retrieving top {k} relevant documents...")
            retrieved_docs = self.vector_store.search(question, k=k)
            
            print(f"‚úÖ Retrieved {len(retrieved_docs)} documents")
            for i, doc in enumerate(retrieved_docs):
                print(f"   {i+1}. {doc['metadata']['title'][:50]}... (score: {doc['similarity_score']:.3f})")
            
            # Step 2: Generate response
            if use_llm:
                print(f"\nü§ñ Generating response with LLM...")
                result = self.llm.generate_response(question, retrieved_docs)
                response_text = result['answer']
            else:
                # Use simple context-based response
                print(f"\nüìù Creating context-based response...")
                response_text = self._create_simple_response(question, retrieved_docs)
            
            elapsed_time = time.time() - start_time
            
            # Log performance
            self.logger.log_query(question, elapsed_time, len(retrieved_docs), True)
            
            print(f"\n‚úÖ Response generated in {elapsed_time:.2f}s")
            
            return {
                'query': question,
                'retrieved_docs': retrieved_docs,
                'response': response_text,
                'latency': elapsed_time,
                'num_docs_retrieved': len(retrieved_docs)
            }
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.logger.log_query(question, elapsed_time, 0, False)
            
            print(f"\n‚ùå Error processing query: {e}")
            
            return {
                'query': question,
                'error': str(e),
                'latency': elapsed_time
            }
    
    def _create_simple_response(self, query: str, retrieved_docs: list) -> str:
        """Create a simple response without LLM"""
        if not retrieved_docs:
            return "‡§ï‡•ç‡§∑‡§Æ‡•ç‡§Ø‡§§‡§æ‡§Æ‡•ç, ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§∏‡•ç‡§Ø ‡§â‡§§‡•ç‡§§‡§∞‡§Ç ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡•á‡§∑‡•Å ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§‡§Æ‡•ç‡•§"
        
        # Combine relevant context
        context_parts = []
        for doc in retrieved_docs:
            context_parts.append(f"„Äê{doc['metadata']['title']}„Äë\n{doc['content'][:300]}")
        
        response = "‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§∏‡•ç‡§Ø ‡§Ü‡§ß‡§æ‡§∞‡•á‡§£ ‡§â‡§§‡•ç‡§§‡§∞‡§Æ‡•ç:\n\n" + "\n\n".join(context_parts)
        return response
    
    def interactive_mode(self):
        """Run interactive query mode"""
        print("\n" + "="*70)
        print("üéØ Interactive Mode - Type your questions (or 'quit' to exit)")
        print("="*70)
        
        while True:
            print("\n")
            question = input("‚ùì Your question: ").strip()
            
            if question.lower() in ['quit', 'exit', 'q']:
                print("\nüëã Goodbye!")
                self.logger.print_statistics()
                break
            
            if not question:
                continue
            
            result = self.query(question, use_llm=False)  # Use simple mode for speed
            
            print("\n" + "‚îÄ"*70)
            print("üí° Response:")
            print("‚îÄ"*70)
            if 'error' in result:
                print(f"‚ùå Error: {result['error']}")
            else:
                print(result['response'])
            print("‚îÄ"*70)


# Main execution
if __name__ == "__main__":
    try:
        # Initialize pipeline
        rag = SanskritRAGPipeline()
        
        # Example queries
        print("\n" + "="*70)
        print("üìã Running Example Queries")
        print("="*70)
        
        queries = [
            "‡§Æ‡•Ç‡§∞‡•ç‡§ñ‡§≠‡•É‡§§‡•ç‡§Ø‡§∏‡•ç‡§Ø ‡§ï‡§•‡§æ ‡§ï‡§ø‡§Æ‡•ç?",
            "‡§ï‡§æ‡§≤‡•Ä‡§¶‡§æ‡§∏‡§∏‡•ç‡§Ø ‡§ö‡§æ‡§§‡•Å‡§∞‡•ç‡§Ø‡§Ç ‡§µ‡§∞‡•ç‡§£‡§Ø‡§§‡•Å",
            "‡§µ‡•É‡§¶‡•ç‡§ß‡§æ‡§Ø‡§æ‡§É ‡§ï‡§•‡§æ‡§Ø‡§æ‡§Ç ‡§ï‡§ø‡§Ç ‡§ò‡§ü‡§ø‡§§‡§Æ‡•ç?"
        ]
        
        for query in queries:
            result = rag.query(query, use_llm=False)  # Use simple mode
            
            print("\n" + "="*70)
            print(f"Query: {result['query']}")
            print("="*70)
            if 'error' not in result:
                print(f"\n{result['response'][:500]}...")
                print(f"\n‚è±Ô∏è  Latency: {result['latency']:.2f}s")
            print("="*70)
        
        # Print statistics
        rag.logger.print_statistics()
        
        # Uncomment to run interactive mode
        # rag.interactive_mode()
        
    except KeyboardInterrupt:
        print("\n\nüëã Interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        import traceback
        traceback.print_exc()